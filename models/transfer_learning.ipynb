{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load yamnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yamnet_model_handle = 'https://www.kaggle.com/models/google/yamnet/TensorFlow2/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mp3(filename):\n",
    "    file_content = tf.io.read_file(filename)\n",
    "    wav = tfio.audio.decode_mp3(file_content)\n",
    "    wav = tf.reduce_mean(wav, axis=1)\n",
    "    sample_rate = tfio.audio.AudioIOTensor(filename, dtype=tf.float32).rate\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = os.path.join('..', 'data', 'xeno-canto')\n",
    "bird_species_df = pd.read_csv('../data/selected_species.csv', sep=',')\n",
    "\n",
    "class_names = []\n",
    "class_id = 0\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for dir_name in os.listdir(os.path.join(data_directory, 'train')):\n",
    "    if dir_name.startswith('.'):\n",
    "        continue\n",
    "    class_name = bird_species_df.loc[bird_species_df['Latin name'] == dir_name]['Polish name'].squeeze()\n",
    "    class_names.append(class_name)\n",
    "\n",
    "    for file_name in os.listdir(os.path.join(data_directory, 'train', dir_name)):\n",
    "        file_path = os.path.join(data_directory, 'train', dir_name, file_name)\n",
    "        X_train.append(file_path)\n",
    "        y_train.append(class_id)\n",
    "\n",
    "    for file_name in os.listdir(os.path.join(data_directory, 'val', dir_name)):\n",
    "        file_path = os.path.join(data_directory, 'val', dir_name, file_name)\n",
    "        X_val.append(file_path)\n",
    "        y_val.append(class_id)\n",
    "\n",
    "    for file_name in os.listdir(os.path.join(data_directory, 'test', dir_name)):\n",
    "        file_path = os.path.join(data_directory, 'test', dir_name, file_name)\n",
    "        X_test.append(file_path)\n",
    "        y_test.append(class_id)\n",
    "    \n",
    "    class_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x000002D166CB3A30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x000002D166CB3A30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x000002D166CB3A30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x000002D166CB3A30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# delete recordings that cannot be decoded\n",
    "for file_path in X_train:\n",
    "    try:\n",
    "        wav = load_mp3(file_path)\n",
    "    except:\n",
    "        os.remove(file_path)\n",
    "\n",
    "for file_path in X_val:\n",
    "    try:\n",
    "        wav = load_mp3(file_path)\n",
    "    except:\n",
    "        os.remove(file_path)\n",
    "\n",
    "for file_path in X_test:\n",
    "    try:\n",
    "        wav = load_mp3(file_path)\n",
    "    except:\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skowronek', 'krzyżówka', 'gęś białoczelna', 'gęś zbożowa', 'jerzyk', 'mewa śmieszka', 'gołąb miejski', 'grzywacz', 'gawron', 'kawka', 'kukułka', 'modraszka', 'oknówka', 'łyska', 'sójka', 'słowik szary', 'słowik rdzawy', 'sroka', 'brzegówka', 'kowalik']\n"
     ]
    }
   ],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\micha\\miniconda3\\envs\\birddetect\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\micha\\miniconda3\\envs\\birddetect\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "def load_mp3_for_map(filename, label):\n",
    "    return load_mp3(filename), label\n",
    "\n",
    "train_data = train_data.map(lambda filename, label: load_mp3_for_map(filename, label))\n",
    "val_data = val_data.map(lambda filename, label: load_mp3_for_map(filename, label))\n",
    "test_data = test_data.map(lambda filename, label: load_mp3_for_map(filename, label))\n",
    "\n",
    "def extract_embeddings(wav_data, label):\n",
    "    _, embeddings, _ = yamnet_model(wav_data)\n",
    "    num_embeddings = tf.shape(embeddings)[0]\n",
    "    return (embeddings,\n",
    "            tf.repeat(label, num_embeddings))\n",
    "\n",
    "train_data = train_data.map(extract_embeddings).unbatch()\n",
    "val_data = val_data.map(extract_embeddings).unbatch()\n",
    "test_data = test_data.map(extract_embeddings).unbatch()\n",
    "\n",
    "train_data = train_data.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_data = val_data.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_data = test_data.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 1024), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(train_data.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,060\n",
      "Trainable params: 535,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1024), dtype=tf.float32,\n",
    "                          name='input_embedding'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_names))\n",
    "], name='my_model')\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                            patience=3,\n",
    "                                            restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1330/1330 [==============================] - 1201s 890ms/step - loss: 0.5954 - accuracy: 0.8547 - val_loss: 10.1473 - val_accuracy: 0.0687\n",
      "Epoch 2/20\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.4309 - accuracy: 0.8811 - val_loss: 7.9826 - val_accuracy: 0.0853\n",
      "Epoch 3/20\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.3444 - accuracy: 0.8971 - val_loss: 9.3059 - val_accuracy: 0.0766\n",
      "Epoch 4/20\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.3094 - accuracy: 0.9076 - val_loss: 8.7802 - val_accuracy: 0.0865\n",
      "Epoch 5/20\n",
      "1330/1330 [==============================] - 16s 12ms/step - loss: 0.2859 - accuracy: 0.9137 - val_loss: 9.9275 - val_accuracy: 0.0895\n"
     ]
    }
   ],
   "source": [
    "history = my_model.fit(train_data,\n",
    "                       epochs=20,\n",
    "                       validation_data=val_data,\n",
    "                       callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490/1490 [==============================] - 585s 392ms/step - loss: 8.1276 - accuracy: 0.0618\n",
      "Loss:  8.127580642700195\n",
      "Accuracy:  0.06181284040212631\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = my_model.evaluate(test_data)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main sound is: kowalik\n"
     ]
    }
   ],
   "source": [
    "testing_file_name = '../data/xeno-canto/test/Luscinia megarhynchos/36984.mp3'\n",
    "wav = load_mp3(testing_file_name)\n",
    "\n",
    "scores, embeddings, spectrogram = yamnet_model(wav)\n",
    "result = my_model(embeddings).numpy()\n",
    "\n",
    "inferred_class = class_names[result.mean(axis=0).argmax()]\n",
    "\n",
    "print(f'The main sound is: {inferred_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend trained model to be able to give it raw wav data as input\n",
    "class ReduceMeanLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, axis=0, **kwargs):\n",
    "    super(ReduceMeanLayer, self).__init__(**kwargs)\n",
    "    self.axis = axis\n",
    "\n",
    "  def call(self, input):\n",
    "    return tf.math.reduce_mean(input, axis=self.axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = './birds_yamnet.keras'\n",
    "\n",
    "input_segment = tf.keras.layers.Input(shape=(), dtype=tf.float32, name='audio')\n",
    "embedding_extraction_layer = hub.KerasLayer(yamnet_model_handle,\n",
    "                                            trainable=False, name='yamnet')\n",
    "_, embeddings_output, _ = embedding_extraction_layer(input_segment)\n",
    "serving_outputs = my_model(embeddings_output)\n",
    "serving_outputs = ReduceMeanLayer(axis=0, name='classifier')(serving_outputs)\n",
    "serving_model = tf.keras.Model(input_segment, serving_outputs)\n",
    "serving_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "reloaded_model = tf.keras.models.load_model(saved_model_path, custom_objects={'KerasLayer':hub.KerasLayer, 'ReduceMeanLayer': ReduceMeanLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main sound is: słowik szary\n"
     ]
    }
   ],
   "source": [
    "reloaded_results = reloaded_model(wav)\n",
    "inferred_class = class_names[tf.math.argmax(reloaded_results)]\n",
    "\n",
    "print(f'The main sound is: {inferred_class}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
