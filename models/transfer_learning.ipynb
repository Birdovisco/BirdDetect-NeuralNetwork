{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load yamnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_mp3(filename):\n",
    "    file_content = tf.io.read_file(filename)\n",
    "    wav = tfio.audio.decode_mp3(file_content)\n",
    "    wav = tf.reduce_mean(wav, axis=1)\n",
    "    sample_rate = tfio.audio.AudioIOTensor(filename, dtype=tf.float32).rate\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '../data/xeno-canto/'\n",
    "bird_species_df = pd.read_csv('../data/selected_species.csv', sep=',')\n",
    "filenames = []\n",
    "targets = []\n",
    "recording_ids = []\n",
    "class_names = []\n",
    "class_id = 0\n",
    "recording_id = 0\n",
    "\n",
    "for dir_name in os.listdir(data_directory):\n",
    "    if dir_name.startswith('.'):\n",
    "        continue\n",
    "    class_name = bird_species_df.loc[bird_species_df['Latin name'] == dir_name]['Polish name'].squeeze()\n",
    "    class_names.append(class_name)\n",
    "\n",
    "    for file_name in os.listdir(data_directory + dir_name)[:20]:\n",
    "        file_path = data_directory + dir_name + '/' + file_name\n",
    "        filenames.append(file_path)\n",
    "        targets.append(class_id)\n",
    "        recording_ids.append(recording_id)\n",
    "        recording_id += 1\n",
    "    \n",
    "    class_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_ds = tf.data.Dataset.from_tensor_slices((filenames, targets, recording_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mp3_for_map(filename, label, recording_id):\n",
    "    return load_mp3(filename), label, recording_id\n",
    "\n",
    "main_ds = main_ds.map(load_mp3_for_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(wav_data, label, recording_id):\n",
    "    _, embeddings, _ = yamnet_model(wav_data)\n",
    "    num_embeddings = tf.shape(embeddings)[0]\n",
    "    return (embeddings,\n",
    "            tf.repeat(label, num_embeddings),\n",
    "            tf.repeat(recording_id, num_embeddings))\n",
    "main_ds = main_ds.map(extract_embeddings).unbatch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recording_ids = random.sample(range(recording_id), int(0.8*recording_id))\n",
    "validation_recording_ids = [x for x in range(recording_id) if x not in train_recording_ids]\n",
    "test_recording_ids = random.sample(validation_recording_ids, int(0.5 * len(validation_recording_ids)))\n",
    "\n",
    "validation_recording_ids = [x for x in validation_recording_ids if x not in test_recording_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_ds = main_ds.cache()\n",
    "\n",
    "def train_filter_condition(embedding, label, recording_id):\n",
    "    return recording_id in train_recording_ids\n",
    "\n",
    "def train_filter_condition_wrapper(embedding, label, recording_id):\n",
    "    return tf.py_function(train_filter_condition, (embedding, label, recording_id), tf.bool)\n",
    "\n",
    "def validation_filter_condition(embedding, label, recording_id):\n",
    "    return recording_id in validation_recording_ids\n",
    "\n",
    "def validation_filter_condition_wrapper(embedding, label, recording_id):\n",
    "    return tf.py_function(validation_filter_condition, (embedding, label, recording_id), tf.bool)\n",
    "\n",
    "def test_filter_condition(embedding, label, recording_id):\n",
    "    return recording_id in test_recording_ids\n",
    "\n",
    "def test_filter_condition_wrapper(embedding, label, recording_id):\n",
    "    return tf.py_function(test_filter_condition, (embedding, label, recording_id), tf.bool)\n",
    "\n",
    "train_ds = cached_ds.filter(train_filter_condition_wrapper)\n",
    "val_ds = cached_ds.filter(validation_filter_condition_wrapper)\n",
    "test_ds = cached_ds.filter(test_filter_condition_wrapper)\n",
    "\n",
    "remove_recording_id_column = lambda embedding, label, recording_id: (embedding, label)\n",
    "\n",
    "train_ds = train_ds.map(remove_recording_id_column)\n",
    "val_ds = val_ds.map(remove_recording_id_column)\n",
    "test_ds = test_ds.map(remove_recording_id_column)\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,060\n",
      "Trainable params: 535,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1024), dtype=tf.float32,\n",
    "                          name='input_embedding'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_names))\n",
    "], name='my_model')\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                            patience=3,\n",
    "                                            restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1078/1078 [==============================] - 1249s 1s/step - loss: 0.6767 - accuracy: 0.8232 - val_loss: 9.2400 - val_accuracy: 0.0990\n",
      "Epoch 2/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.5190 - accuracy: 0.8563 - val_loss: 8.5111 - val_accuracy: 0.1109\n",
      "Epoch 3/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.4125 - accuracy: 0.8770 - val_loss: 8.3131 - val_accuracy: 0.1259\n",
      "Epoch 4/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.3530 - accuracy: 0.8958 - val_loss: 8.1821 - val_accuracy: 0.1340\n",
      "Epoch 5/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.3384 - accuracy: 0.8994 - val_loss: 8.5636 - val_accuracy: 0.1188\n",
      "Epoch 6/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.3152 - accuracy: 0.9086 - val_loss: 8.4993 - val_accuracy: 0.1254\n",
      "Epoch 7/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.2725 - accuracy: 0.9177 - val_loss: 8.5793 - val_accuracy: 0.1624\n",
      "Epoch 8/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.2625 - accuracy: 0.9225 - val_loss: 9.2495 - val_accuracy: 0.1441\n",
      "Epoch 9/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.2381 - accuracy: 0.9280 - val_loss: 9.3289 - val_accuracy: 0.1351\n",
      "Epoch 10/20\n",
      "1078/1078 [==============================] - 10s 10ms/step - loss: 0.2298 - accuracy: 0.9304 - val_loss: 8.5921 - val_accuracy: 0.1858\n",
      "Epoch 11/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.2006 - accuracy: 0.9392 - val_loss: 8.9727 - val_accuracy: 0.1688\n",
      "Epoch 12/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.2037 - accuracy: 0.9375 - val_loss: 9.1827 - val_accuracy: 0.1869\n",
      "Epoch 13/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.1846 - accuracy: 0.9431 - val_loss: 9.0316 - val_accuracy: 0.1860\n",
      "Epoch 14/20\n",
      "1078/1078 [==============================] - 10s 10ms/step - loss: 0.1835 - accuracy: 0.9449 - val_loss: 9.2831 - val_accuracy: 0.2140\n",
      "Epoch 15/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.1946 - accuracy: 0.9473 - val_loss: 10.1902 - val_accuracy: 0.1479\n",
      "Epoch 16/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.1765 - accuracy: 0.9473 - val_loss: 9.0370 - val_accuracy: 0.1955\n",
      "Epoch 17/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.1754 - accuracy: 0.9505 - val_loss: 9.7073 - val_accuracy: 0.2081\n",
      "Epoch 18/20\n",
      "1078/1078 [==============================] - 10s 9ms/step - loss: 0.1602 - accuracy: 0.9529 - val_loss: 9.2271 - val_accuracy: 0.2330\n",
      "Epoch 19/20\n",
      "1078/1078 [==============================] - 10s 10ms/step - loss: 0.1604 - accuracy: 0.9534 - val_loss: 9.0448 - val_accuracy: 0.2244\n",
      "Epoch 20/20\n",
      "1078/1078 [==============================] - 10s 10ms/step - loss: 0.1545 - accuracy: 0.9550 - val_loss: 10.0057 - val_accuracy: 0.1940\n"
     ]
    }
   ],
   "source": [
    "history = my_model.fit(train_ds,\n",
    "                       epochs=20,\n",
    "                       validation_data=val_ds,\n",
    "                       callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 130s 841ms/step - loss: 7.3547 - accuracy: 0.3432\n",
      "Loss:  7.3546929359436035\n",
      "Accuracy:  0.343235045671463\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = my_model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main sound is: kowalik\n"
     ]
    }
   ],
   "source": [
    "testing_file_name = '../data/xeno-canto/Luscinia megarhynchos/19660.mp3'\n",
    "wav = load_mp3(testing_file_name)\n",
    "\n",
    "scores, embeddings, spectrogram = yamnet_model(wav)\n",
    "result = my_model(embeddings).numpy()\n",
    "\n",
    "inferred_class = class_names[result.mean(axis=0).argmax()]\n",
    "\n",
    "print(f'The main sound is: {inferred_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend trained model to be able to give it raw wav data as input\n",
    "class ReduceMeanLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, axis=0, **kwargs):\n",
    "    super(ReduceMeanLayer, self).__init__(**kwargs)\n",
    "    self.axis = axis\n",
    "\n",
    "  def call(self, input):\n",
    "    return tf.math.reduce_mean(input, axis=self.axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = './birds_yamnet.keras'\n",
    "\n",
    "input_segment = tf.keras.layers.Input(shape=(), dtype=tf.float32, name='audio')\n",
    "embedding_extraction_layer = hub.KerasLayer(yamnet_model_handle,\n",
    "                                            trainable=False, name='yamnet')\n",
    "_, embeddings_output, _ = embedding_extraction_layer(input_segment)\n",
    "serving_outputs = my_model(embeddings_output)\n",
    "serving_outputs = ReduceMeanLayer(axis=0, name='classifier')(serving_outputs)\n",
    "serving_model = tf.keras.Model(input_segment, serving_outputs)\n",
    "serving_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "reloaded_model = tf.keras.models.load_model(saved_model_path, custom_objects={'KerasLayer':hub.KerasLayer, 'ReduceMeanLayer': ReduceMeanLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main sound is: kowalik\n"
     ]
    }
   ],
   "source": [
    "reloaded_results = reloaded_model(wav)\n",
    "inferred_class = class_names[tf.math.argmax(reloaded_results)]\n",
    "\n",
    "print(f'The main sound is: {inferred_class}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
